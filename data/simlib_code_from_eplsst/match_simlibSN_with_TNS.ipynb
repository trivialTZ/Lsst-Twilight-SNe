{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbd372d",
   "metadata": {},
   "source": [
    "# Match SIMLIB WFD entries to TNS\n",
    "\n",
    "This notebook matches SIMLIB WFD events to TNS transients using redshift, discovery time, and sky position. It then writes:\n",
    "\n",
    "- A match table (`WFD_to_TNS_match_table.csv`)\n",
    "- A list of unmatched TNS entries within the date window (`TNS_unmatched.csv`)\n",
    "- An annotated SIMLIB with match comments injected after each `NOBS/REDSHIFT` line (`SIMLIB_MATCHED_ANNOTATED.SIMLIB`)\n",
    "\n",
    "The matching is **one-to-one** on TNS objects (each TNS entry is used at most once), and the matching is greedy over SIMLIB entries ordered by first observation time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19995444",
   "metadata": {},
   "source": [
    "## Imports and utilities\n",
    "\n",
    "We define:\n",
    "- A simple UTC datetime to MJD converter.\n",
    "- An angular separation function using the great-circle formula.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd23cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import argparse\n",
    "import datetime as dt\n",
    "from bisect import bisect_left, bisect_right\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8cf17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# time conversion: datetime -> MJD\n",
    "# MJD(1970-01-01 00:00:00 UTC) = 40587.0\n",
    "# (Ignores leap seconds; for 30-day tolerance this is fine.)\n",
    "# -----------------------------\n",
    "\n",
    "def datetime_to_mjd(d: dt.datetime) -> float:\n",
    "    epoch = dt.datetime(1970, 1, 1)\n",
    "    return 40587.0 + (d - epoch).total_seconds() / 86400.0\n",
    "\n",
    "\n",
    "def ang_sep_deg(ra1, dec1, ra2, dec2) -> float:\n",
    "    \"\"\"Great-circle angular separation in degrees. Inputs in degrees.\"\"\"\n",
    "    r1 = math.radians(ra1)\n",
    "    d1 = math.radians(dec1)\n",
    "    r2 = math.radians(ra2)\n",
    "    d2 = math.radians(dec2)\n",
    "    cosang = math.sin(d1) * math.sin(d2) + math.cos(d1) * math.cos(d2) * math.cos(r1 - r2)\n",
    "    cosang = max(-1.0, min(1.0, cosang))\n",
    "    return math.degrees(math.acos(cosang))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b770820",
   "metadata": {},
   "source": [
    "## SIMLIB parsing\n",
    "\n",
    "We parse the SIMLIB into per-LIBID records and keep the original lines so we can inject match comments later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f25b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# SIMLIB parsing\n",
    "# -----------------------------\n",
    "\n",
    "def parse_simlib(simlib_path: str):\n",
    "    \"\"\"\n",
    "    Parse SIMLIB into records list (LIBID, RA, DEC, REDSHIFT, first_mjd).\n",
    "    Also returns raw lines for rewriting/annotation.\n",
    "    \"\"\"\n",
    "    with open(simlib_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    records = []\n",
    "    current = None\n",
    "    in_block = False\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"LIBID:\"):\n",
    "            m = re.search(r\"LIBID:\\s*([0-9]+)\", line)\n",
    "            libid = int(m.group(1)) if m else None\n",
    "            current = {\n",
    "                \"LIBID\": libid,\n",
    "                \"RA\": None,\n",
    "                \"DEC\": None,\n",
    "                \"REDSHIFT\": None,\n",
    "                \"first_mjd\": None,\n",
    "                \"line_nobs\": None,\n",
    "            }\n",
    "            in_block = True\n",
    "\n",
    "        elif in_block and line.strip().startswith(\"RA:\"):\n",
    "            m = re.search(r\"RA:\\s*([0-9.+-Ee]+)\\s+DEC:\\s*([0-9.+-Ee]+)\", line)\n",
    "            if m:\n",
    "                current[\"RA\"] = float(m.group(1))\n",
    "                current[\"DEC\"] = float(m.group(2))\n",
    "\n",
    "        elif in_block and (\"NOBS:\" in line and \"REDSHIFT:\" in line):\n",
    "            m = re.search(r\"REDSHIFT:\\s*([0-9.+-Ee]+)\", line)\n",
    "            if m:\n",
    "                current[\"REDSHIFT\"] = float(m.group(1))\n",
    "            current[\"line_nobs\"] = i\n",
    "\n",
    "        elif in_block and line.startswith(\"S:\"):\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    mjd = float(parts[1])\n",
    "                    # robust: take min, even if lines are not sorted\n",
    "                    if current[\"first_mjd\"] is None or mjd < current[\"first_mjd\"]:\n",
    "                        current[\"first_mjd\"] = mjd\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        elif in_block and line.strip().startswith(\"END_LIBID\"):\n",
    "            records.append(current)\n",
    "            current = None\n",
    "            in_block = False\n",
    "\n",
    "    return records, lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb5d6a8",
   "metadata": {},
   "source": [
    "## Matching logic\n",
    "\n",
    "We do a 1-to-1 greedy match of SIMLIB entries to TNS objects, constrained by:\n",
    "\n",
    "- Redshift tolerance (`z_tol`)\n",
    "- Discovery time tolerance in days (`t_tol`)\n",
    "- Angular separation tolerance (`ang_tol`, degrees)\n",
    "\n",
    "The best candidate within tolerances is selected using a normalized quadratic score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Matching (WFD/SIMLIB-driven, 1-to-1 on TNS)\n",
    "# -----------------------------\n",
    "\n",
    "def match_wfd_to_tns(records, df_tns, z_tol=0.005, t_tol=30.0, ang_tol=120.0):\n",
    "    # Sort TNS by redshift for fast z-window lookup\n",
    "    tns = df_tns.sort_values(\"redshift\").reset_index(drop=True)\n",
    "    z_arr = tns[\"redshift\"].to_numpy()\n",
    "    used = np.zeros(len(tns), dtype=bool)\n",
    "\n",
    "    # sort WFD by time (optional but reasonable for greedy)\n",
    "    wfd_sorted = sorted(\n",
    "        [r for r in records if r.get(\"first_mjd\") is not None and r.get(\"REDSHIFT\") is not None],\n",
    "        key=lambda r: r[\"first_mjd\"],\n",
    "    )\n",
    "\n",
    "    matches = []\n",
    "    for r in wfd_sorted:\n",
    "        z0 = r[\"REDSHIFT\"]\n",
    "        mjd0 = r[\"first_mjd\"]\n",
    "\n",
    "        lo = bisect_left(z_arr, z0 - z_tol)\n",
    "        hi = bisect_right(z_arr, z0 + z_tol)\n",
    "\n",
    "        best = None\n",
    "        for j in range(lo, hi):\n",
    "            if used[j]:\n",
    "                continue\n",
    "\n",
    "            mjd_t = float(tns.at[j, \"discovery_mjd\"])\n",
    "            dt_days = abs(mjd_t - mjd0)\n",
    "            if dt_days > t_tol:\n",
    "                continue\n",
    "\n",
    "            ra_t = float(tns.at[j, \"ra\"])\n",
    "            dec_t = float(tns.at[j, \"declination\"])\n",
    "\n",
    "            if r.get(\"RA\") is not None and r.get(\"DEC\") is not None:\n",
    "                ang = ang_sep_deg(r[\"RA\"], r[\"DEC\"], ra_t, dec_t)\n",
    "            else:\n",
    "                ang = 0.0\n",
    "\n",
    "            if ang > ang_tol:\n",
    "                continue\n",
    "\n",
    "            dz = abs(float(z_arr[j]) - z0)\n",
    "            score = (dz / z_tol) ** 2 + (dt_days / t_tol) ** 2 + (ang / ang_tol) ** 2\n",
    "\n",
    "            if best is None or score < best[\"score\"]:\n",
    "                best = {\"j\": j, \"score\": score, \"dz\": dz, \"dt\": dt_days, \"ang\": ang}\n",
    "\n",
    "        if best is not None:\n",
    "            j = best[\"j\"]\n",
    "            used[j] = True\n",
    "            matches.append(\n",
    "                {\n",
    "                    \"LIBID\": int(r[\"LIBID\"]),\n",
    "                    \"wfd_z\": float(z0),\n",
    "                    \"wfd_ra\": r.get(\"RA\"),\n",
    "                    \"wfd_dec\": r.get(\"DEC\"),\n",
    "                    \"wfd_first_mjd\": float(mjd0),\n",
    "                    \"TNS_objid\": int(tns.at[j, \"objid\"]),\n",
    "                    \"TNS_name\": f\"{tns.at[j,'name_prefix']}{tns.at[j,'name']}\",\n",
    "                    \"tns_z\": float(tns.at[j, \"redshift\"]),\n",
    "                    \"tns_ra\": float(tns.at[j, \"ra\"]),\n",
    "                    \"tns_dec\": float(tns.at[j, \"declination\"]),\n",
    "                    \"tns_discovery_mjd\": float(tns.at[j, \"discovery_mjd\"]),\n",
    "                    \"dz\": float(best[\"dz\"]),\n",
    "                    \"dt_days\": float(best[\"dt\"]),\n",
    "                    \"ang_sep_deg\": float(best[\"ang\"]),\n",
    "                    \"score\": float(best[\"score\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    match_df = pd.DataFrame(matches).sort_values(\"LIBID\")\n",
    "    unmatched_tns = tns.loc[~used].copy()\n",
    "    return match_df, unmatched_tns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f273a3f",
   "metadata": {},
   "source": [
    "## Annotate SIMLIB\n",
    "\n",
    "For matched LIBIDs, we inject a single-line comment after the `NOBS/REDSHIFT` line with the TNS match details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_simlib_lines(lines, match_df):\n",
    "    # map LIBID -> match row (namedtuple)\n",
    "    match_map = {int(row.LIBID): row for row in match_df.itertuples(index=False)}\n",
    "\n",
    "    new_lines = []\n",
    "    current_libid = None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"LIBID:\"):\n",
    "            m = re.search(r\"LIBID:\\s*([0-9]+)\", line)\n",
    "            current_libid = int(m.group(1)) if m else None\n",
    "            new_lines.append(line)\n",
    "            continue\n",
    "\n",
    "        new_lines.append(line)\n",
    "\n",
    "        if (\n",
    "            current_libid is not None\n",
    "            and (\"NOBS:\" in line and \"REDSHIFT:\" in line)\n",
    "            and current_libid in match_map\n",
    "        ):\n",
    "            row = match_map[current_libid]\n",
    "            comment = (\n",
    "                f\"# MATCH_TNS: objid={row.TNS_objid} name={row.TNS_name} \"\n",
    "                f\"z_tns={row.tns_z:.5f} mjd_tns={row.tns_discovery_mjd:.5f} \"\n",
    "                f\"dt_days={row.dt_days:.2f} ang_deg={row.ang_sep_deg:.2f}\n",
    "\"\n",
    "            )\n",
    "            new_lines.append(comment)\n",
    "\n",
    "    return new_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0c2a6",
   "metadata": {},
   "source": [
    "## I/O and end-to-end run\n",
    "\n",
    "Set paths and matching tolerances, then run the workflow. The defaults match the script version you provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23077fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "TNS_CSV = \"../TNS_with_WFD_fake_injected.csv\"\n",
    "SIMLIB_PATH = \"_10y_LOWZ_REDSHIFT_LT015_FROM_SIMDATA.SIMLIB\"\n",
    "\n",
    "# Outputs\n",
    "OUT_UNMATCHED = \"TNS_unmatched.csv\"\n",
    "OUT_MATCH = \"WFD_to_TNS_match_table.csv\"\n",
    "OUT_ANNOTATED = \"SIMLIB_MATCHED_ANNOTATED.SIMLIB\"\n",
    "\n",
    "# Matching tolerances\n",
    "Z_TOL = 0.005\n",
    "T_TOL_DAYS = 30.0\n",
    "ANG_TOL_DEG = 120.0\n",
    "\n",
    "# Discovery date window (inclusive of start, exclusive of end)\n",
    "START_DATE = \"2022-10-01\"\n",
    "END_DATE = \"2024-01-01\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- read & filter TNS\n",
    "\n",
    "df = pd.read_csv(TNS_CSV)\n",
    "df[\"discovery_dt\"] = pd.to_datetime(df[\"discoverydate\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"discovery_dt\", \"redshift\", \"ra\", \"declination\"]).copy()\n",
    "\n",
    "start = pd.Timestamp(START_DATE + \" 00:00:00\")\n",
    "end = pd.Timestamp(END_DATE + \" 00:00:00\")\n",
    "df = df[(df[\"discovery_dt\"] >= start) & (df[\"discovery_dt\"] < end)].copy()\n",
    "\n",
    "df[\"discovery_mjd\"] = df[\"discovery_dt\"].apply(lambda x: datetime_to_mjd(x.to_pydatetime()))\n",
    "\n",
    "# --- parse simlib\n",
    "records, lines = parse_simlib(SIMLIB_PATH)\n",
    "\n",
    "# --- match\n",
    "match_df, unmatched_tns = match_wfd_to_tns(\n",
    "    records,\n",
    "    df,\n",
    "    z_tol=Z_TOL,\n",
    "    t_tol=T_TOL_DAYS,\n",
    "    ang_tol=ANG_TOL_DEG,\n",
    ")\n",
    "\n",
    "# --- write match table\n",
    "match_df.to_csv(OUT_MATCH, index=False)\n",
    "\n",
    "# --- write unmatched TNS CSV (keep original columns + discovery_mjd)\n",
    "original_cols = [c for c in df.columns if c in pd.read_csv(TNS_CSV, nrows=1).columns]\n",
    "out_df = unmatched_tns[original_cols].copy()\n",
    "out_df[\"discovery_mjd\"] = unmatched_tns[\"discovery_mjd\"].values\n",
    "out_df.to_csv(OUT_UNMATCHED, index=False)\n",
    "\n",
    "# --- write annotated simlib\n",
    "annotated_lines = annotate_simlib_lines(lines, match_df)\n",
    "with open(OUT_ANNOTATED, \"w\") as f:\n",
    "    f.writelines(annotated_lines)\n",
    "\n",
    "print(f\"Matched pairs: {len(match_df)}\")\n",
    "print(f\"Unmatched TNS (in date window): {len(out_df)}\")\n",
    "print(\"Wrote:\")\n",
    "print(\"  \", OUT_UNMATCHED)\n",
    "print(\"  \", OUT_MATCH)\n",
    "print(\"  \", OUT_ANNOTATED)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}